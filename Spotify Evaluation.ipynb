{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f2da70-a3e5-418a-a3c0-6bbb69ccf445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /Users/admin/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (t:Track)\n",
      "RETURN max(t.streams)\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'max(t.streams)': 3703895074}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (t:Track)\n",
      "RETURN avg(t.streams)\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'avg(t.streams)': 513597931.3137464}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (a:Artist)-[:PERFORMED]->(t:Track)\n",
      "RETURN a.name, count(t) AS trackCount\n",
      "ORDER BY trackCount DESC\n",
      "LIMIT 1\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'a.name': 'Bad Bunny', 'trackCount': 40}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: valence)} {position: line: 3, column: 18, offset: 40} for query: 'cypher\\nMATCH (t:Track)\\nRETURN t.name, t.valence\\nORDER BY t.valence DESC\\nLIMIT 1\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (t:Track)\n",
      "RETURN t.name, t.valence\n",
      "ORDER BY t.valence DESC\n",
      "LIMIT 1\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'t.name': 'Seven (feat. Latto) (Explicit Ver.)', 't.valence': None}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (t:Track)\n",
      "RETURN t.released_month, count(t) AS num_releases\n",
      "ORDER BY num_releases DESC\n",
      "LIMIT 1\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'t.released_month': 1, 'num_releases': 134}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (t:Track)\n",
      "RETURN avg(t.spotify_playlists)\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'avg(t.spotify_playlists)': 5200.124868835249}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (t:Track)\n",
      "RETURN t.name, t.released_day, t.released_month, t.released_year\n",
      "ORDER BY t.released_year, t.released_month, t.released_day\n",
      "LIMIT 1\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'t.name': 'Agudo Mï¿½ï¿½gi', 't.released_day': 1, 't.released_month': 1, 't.released_year': 1930}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (t:Track)\n",
      "RETURN sum(t.streams)\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'sum(t.streams)': 489458828542}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (a:Artist)-[:PERFORMED]->(t:Track)\n",
      "WITH a, avg(t.spotify_charts) AS avgDanceability, count(t) AS trackCount\n",
      "ORDER BY avgDanceability DESC\n",
      "LIMIT 1\n",
      "RETURN a.name AS artistName, avgDanceability\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'artistName': 'Latto', 'avgDanceability': 147.0}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (t:Track)\n",
      "RETURN t.name, t.spotify_charts\n",
      "ORDER BY t.spotify_charts DESC\n",
      "LIMIT 1\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'t.name': 'Seven (feat. Latto) (Explicit Ver.)', 't.spotify_charts': 147}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Detailed Evaluation Results:\n",
      "                                               Query  \\\n",
      "0             What is the highest number of streams?   \n",
      "1          What is the average energy of all tracks?   \n",
      "2              Which artist appears most frequently?   \n",
      "3                Which song has the highest valence?   \n",
      "4            Which month had the most song releases?   \n",
      "5  What is the average number of Spotify playlist...   \n",
      "6          Which song had the earliest release date?   \n",
      "7  What is the total number of streams for all so...   \n",
      "8  Which artist has the highest average danceabil...   \n",
      "9     Which song appears in the most Spotify charts?   \n",
      "\n",
      "                                     Generated Query  \\\n",
      "0   cypher\\nMATCH (t:Track)\\nRETURN max(t.streams)\\n   \n",
      "1   cypher\\nMATCH (t:Track)\\nRETURN avg(t.streams)\\n   \n",
      "2  cypher\\nMATCH (a:Artist)-[:PERFORMED]->(t:Trac...   \n",
      "3  cypher\\nMATCH (t:Track)\\nRETURN t.name, t.vale...   \n",
      "4  cypher\\nMATCH (t:Track)\\nRETURN t.released_mon...   \n",
      "5  cypher\\nMATCH (t:Track)\\nRETURN avg(t.spotify_...   \n",
      "6  cypher\\nMATCH (t:Track)\\nRETURN t.name, t.rele...   \n",
      "7   cypher\\nMATCH (t:Track)\\nRETURN sum(t.streams)\\n   \n",
      "8  cypher\\nMATCH (a:Artist)-[:PERFORMED]->(t:Trac...   \n",
      "9  cypher\\nMATCH (t:Track)\\nRETURN t.name, t.spot...   \n",
      "\n",
      "                                   Retrieved Context  \\\n",
      "0                   [{'max(t.streams)': 3703895074}]   \n",
      "1            [{'avg(t.streams)': 513597931.3137464}]   \n",
      "2        [{'a.name': 'Bad Bunny', 'trackCount': 40}]   \n",
      "3  [{'t.name': 'Seven (feat. Latto) (Explicit Ver...   \n",
      "4     [{'t.released_month': 1, 'num_releases': 134}]   \n",
      "5  [{'avg(t.spotify_playlists)': 5200.124868835249}]   \n",
      "6  [{'t.name': 'Agudo Mï¿½ï¿½gi', 't.released_day...   \n",
      "7                 [{'sum(t.streams)': 489458828542}]   \n",
      "8  [{'artistName': 'Latto', 'avgDanceability': 14...   \n",
      "9  [{'t.name': 'Seven (feat. Latto) (Explicit Ver...   \n",
      "\n",
      "                                    Predicted Answer  \\\n",
      "0       The highest number of streams is 3703895074.   \n",
      "1    The average of all tracks is 513597931.3137464.   \n",
      "2                 Bad Bunny appears most frequently.   \n",
      "3  I am sorry, I cannot answer the question becau...   \n",
      "4  January had the most song releases with 134 re...   \n",
      "5  The average number of Spotify playlists a trac...   \n",
      "6  Agudo Mï¿½ï¿½gi had the earliest release date,...   \n",
      "7  The total number of streams for all songs is 4...   \n",
      "8  Latto has the highest average danceability acr...   \n",
      "9  Seven (feat. Latto) (Explicit Ver.) appears in...   \n",
      "\n",
      "                                     Expected Answer  ROUGE-1 Score  \\\n",
      "0        The highest number of streams is 3703895074       1.000000   \n",
      "1  The average energy of all tracks is 513597931....       0.941176   \n",
      "2  The artist that appears most frequently is \"Ba...       0.428571   \n",
      "3      The song with the highest valence is \"Seven\"        0.240000   \n",
      "4        The month with the most releases is January       0.625000   \n",
      "5               The 5200.124868835249 is M playlists       0.526316   \n",
      "6  The song with the earliest release is \"Agudo M...       0.285714   \n",
      "7        The total number of streams is 489458828542       0.823529   \n",
      "8  The artist with highest average danceability i...       0.352941   \n",
      "9  The song with most Spotify chart appearances i...       0.100000   \n",
      "\n",
      "   ROUGE-2 Score  ROUGE-L Score  \n",
      "0       1.000000       1.000000  \n",
      "1       0.800000       0.941176  \n",
      "2       0.333333       0.428571  \n",
      "3       0.000000       0.160000  \n",
      "4       0.133333       0.375000  \n",
      "5       0.117647       0.421053  \n",
      "6       0.210526       0.285714  \n",
      "7       0.666667       0.823529  \n",
      "8       0.266667       0.352941  \n",
      "9       0.000000       0.100000  \n",
      "\n",
      "Overall Metrics:\n",
      "{'Average ROUGE-1 Score': 0.5323248514660114, 'Average ROUGE-2 Score': 0.35281733364076306, 'Average ROUGE-L Score': 0.48879853567653775}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Evaluation metrics libraries\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge import Rouge\n",
    "\n",
    "# NLTK resources\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve environment variables\n",
    "NEO4J_URL = os.getenv(\"NEO4J_URL\", \"bolt://localhost:7687\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USER\", \"neo4j\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PW\", \"admin123\")\n",
    "NEO4J_DATABASE = os.getenv(\"NEO4J_DB\", \"spotify1\")\n",
    "\n",
    "GEMINI_API = os.getenv(\"GEMINI_API\", \"\")\n",
    "\n",
    "@st.cache_resource\n",
    "def graph_chain():\n",
    "    graph = Neo4jGraph(NEO4J_URL, NEO4J_USER, NEO4J_PASSWORD, NEO4J_DATABASE)\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.0-flash-lite\", google_api_key=GEMINI_API, temperature=0\n",
    "    )\n",
    "    chain = GraphCypherQAChain.from_llm(allow_dangerous_requests=True,\n",
    "        graph=graph, llm=llm, return_intermediate_steps=True, verbose=True\n",
    "    )\n",
    "    return chain\n",
    "\n",
    "def infer(chain, prompt):\n",
    "    \"\"\"\n",
    "    Generate response using the RAG system\n",
    "    \n",
    "    Args:\n",
    "        chain: GraphCypherQAChain\n",
    "        prompt: Input query\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (generated query, retrieved context, result)\n",
    "    \"\"\"\n",
    "    response = chain.invoke(prompt)\n",
    "    query = response[\"intermediate_steps\"][0][\"query\"]\n",
    "    context = response[\"intermediate_steps\"][1][\"context\"]\n",
    "    result = response[\"result\"]\n",
    "    return query, context, result\n",
    "\n",
    "class RAGEvaluator:\n",
    "    def __init__(self, ground_truth_data):\n",
    "        \"\"\"\n",
    "        Initialize RAG Evaluator with ground truth data\n",
    "        \n",
    "        Args:\n",
    "            ground_truth_data (list): List of dictionaries with 'query' and 'expected_answer' keys\n",
    "        \"\"\"\n",
    "        self.ground_truth_data = ground_truth_data\n",
    "        self.evaluation_results = []\n",
    "        self.rouge_scorer = Rouge()\n",
    "    \n",
    "    def calculate_bleu_score(self, predicted, expected):\n",
    "        \"\"\"\n",
    "        Calculate BLEU score\n",
    "        \n",
    "        Args:\n",
    "            predicted (str): Predicted answer\n",
    "            expected (str): Expected answer\n",
    "        \n",
    "        Returns:\n",
    "            float: BLEU score\n",
    "        \"\"\"\n",
    "        # Tokenize the sentences\n",
    "        predicted_tokens = nltk.word_tokenize(predicted.lower())\n",
    "        expected_tokens = [nltk.word_tokenize(expected.lower())]\n",
    "        \n",
    "        # Calculate BLEU score\n",
    "        try:\n",
    "            bleu_score = sentence_bleu(expected_tokens, predicted_tokens)\n",
    "        except ZeroDivisionError:\n",
    "            bleu_score = 0\n",
    "        \n",
    "        return bleu_score\n",
    "    \n",
    "    def calculate_rouge_scores(self, predicted, expected):\n",
    "        \"\"\"\n",
    "        Calculate ROUGE scores\n",
    "        \n",
    "        Args:\n",
    "            predicted (str): Predicted answer\n",
    "            expected (str): Expected answer\n",
    "        \n",
    "        Returns:\n",
    "            dict: ROUGE-1, ROUGE-2, and ROUGE-L scores\n",
    "        \"\"\"\n",
    "        try:\n",
    "            rouge_scores = self.rouge_scorer.get_scores(predicted, expected)[0]\n",
    "            return {\n",
    "                'rouge-1': rouge_scores['rouge-1']['f'],\n",
    "                'rouge-2': rouge_scores['rouge-2']['f'],\n",
    "                'rouge-l': rouge_scores['rouge-l']['f']\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating ROUGE scores: {e}\")\n",
    "            return {\n",
    "                'rouge-1': 0,\n",
    "                'rouge-2': 0,\n",
    "                'rouge-l': 0\n",
    "            }\n",
    "    \n",
    "    def calculate_exact_match(self, predicted, expected):\n",
    "        \"\"\"\n",
    "        Calculate exact match score\n",
    "        \n",
    "        Args:\n",
    "            predicted (str): Predicted answer\n",
    "            expected (str): Expected answer\n",
    "        \n",
    "        Returns:\n",
    "            float: Exact match score (0 or 1)\n",
    "        \"\"\"\n",
    "        return 1 if predicted.strip().lower() == expected.strip().lower() else 0\n",
    "    \n",
    "    def calculate_partial_match(self, predicted, expected, threshold=0.7):\n",
    "        \"\"\"\n",
    "        Calculate partial match score using word overlap\n",
    "        \n",
    "        Args:\n",
    "            predicted (str): Predicted answer\n",
    "            expected (str): Expected answer\n",
    "            threshold (float): Matching threshold\n",
    "        \n",
    "        Returns:\n",
    "            float: Partial match score\n",
    "        \"\"\"\n",
    "        predicted_words = set(predicted.lower().split())\n",
    "        expected_words = set(expected.lower().split())\n",
    "        \n",
    "        overlap = len(predicted_words.intersection(expected_words))\n",
    "        max_words = max(len(predicted_words), len(expected_words))\n",
    "        \n",
    "        return 1 if overlap / max_words >= threshold else 0\n",
    "    \n",
    "    def evaluate_relevance(self, context, expected_keywords):\n",
    "        \"\"\"\n",
    "        Evaluate context relevance\n",
    "        \n",
    "        Args:\n",
    "            context (str): Retrieved context\n",
    "            expected_keywords (list): List of keywords expected in context\n",
    "        \n",
    "        Returns:\n",
    "            float: Relevance score\n",
    "        \"\"\"\n",
    "        context_lower = context.lower()\n",
    "        keyword_matches = [\n",
    "            1 if keyword.lower() in context_lower else 0 \n",
    "            for keyword in expected_keywords\n",
    "        ]\n",
    "        return np.mean(keyword_matches) if keyword_matches else 0\n",
    "    \n",
    "    def run_evaluation(self, chain):\n",
    "        \"\"\"\n",
    "        Run comprehensive evaluation of RAG system\n",
    "        \n",
    "        Args:\n",
    "            chain: GraphCypherQAChain\n",
    "        \n",
    "        Returns:\n",
    "            pandas.DataFrame: Evaluation metrics\n",
    "        \"\"\"\n",
    "        for item in self.ground_truth_data:\n",
    "            query = item['query']\n",
    "            expected_answer = item['expected_answer']\n",
    "            expected_keywords = item.get('expected_keywords', [])\n",
    "            \n",
    "            # Generate RAG response\n",
    "            generated_query, retrieved_context, predicted_answer = infer(chain, query)\n",
    "            \n",
    "            # Calculate evaluation metrics\n",
    "            #exact_match = self.calculate_exact_match(predicted_answer, expected_answer)\n",
    "            #partial_match = self.calculate_partial_match(predicted_answer, expected_answer)\n",
    "            #context_relevance = self.calculate_relevance(retrieved_context, expected_keywords)\n",
    "            \n",
    "            # Calculate BLEU and ROUGE scores\n",
    "            #bleu_score = self.calculate_bleu_score(predicted_answer, expected_answer)\n",
    "            rouge_scores = self.calculate_rouge_scores(predicted_answer, expected_answer)\n",
    "            \n",
    "            # Collect evaluation results\n",
    "            self.evaluation_results.append({\n",
    "                'Query': query,\n",
    "                'Generated Query': generated_query,\n",
    "                'Retrieved Context': retrieved_context,\n",
    "                'Predicted Answer': predicted_answer,\n",
    "                'Expected Answer': expected_answer,\n",
    "                #'Exact Match': exact_match,\n",
    "                #'Partial Match': partial_match,\n",
    "                #'Context Relevance': context_relevance,\n",
    "                #'BLEU Score': bleu_score,\n",
    "                'ROUGE-1 Score': rouge_scores['rouge-1'],\n",
    "                'ROUGE-2 Score': rouge_scores['rouge-2'],\n",
    "                'ROUGE-L Score': rouge_scores['rouge-l']\n",
    "            })\n",
    "        \n",
    "        # Convert results to DataFrame\n",
    "        df_results = pd.DataFrame(self.evaluation_results)\n",
    "        \n",
    "        # Calculate overall metrics\n",
    "        metrics = {\n",
    "            #'Average Exact Match': df_results['Exact Match'].mean(),\n",
    "            #'Average Partial Match': df_results['Partial Match'].mean(),\n",
    "            #'Average Context Relevance': df_results['Context Relevance'].mean(),\n",
    "            #'Average BLEU Score': df_results['BLEU Score'].mean(),\n",
    "            'Average ROUGE-1 Score': df_results['ROUGE-1 Score'].mean(),\n",
    "            'Average ROUGE-2 Score': df_results['ROUGE-2 Score'].mean(),\n",
    "            'Average ROUGE-L Score': df_results['ROUGE-L Score'].mean()\n",
    "        }\n",
    "        \n",
    "        return df_results, metrics\n",
    "\n",
    "def main():\n",
    "    # Example ground truth data with multiple queries\n",
    "   \n",
    "    ground_truth_data = [\n",
    "        {\n",
    "            'query': 'What is the highest number of streams?',\n",
    "            'expected_answer': 'The highest number of streams is 3703895074',\n",
    "            'expected_keywords': ['highest', 'streams', '3703895074']\n",
    "        },\n",
    "        # {\n",
    "        #     'query': 'Which track has the lowest danceability?',\n",
    "        #     'expected_answer': 'The track with the lowest danceability is \"vampire\" with 51%',\n",
    "        #     'expected_keywords': ['lowest', 'danceability', 'vampire', '51']\n",
    "        # },\n",
    "        # {\n",
    "        #     'query': 'How many songs were released in 2023?',\n",
    "        #     'expected_answer': 'There are X songs released in 2023',\n",
    "        #     'expected_keywords': ['songs', 'released', '2023']\n",
    "        # },\n",
    "        {\n",
    "            'query': 'What is the average energy of all tracks?',\n",
    "            'expected_answer': 'The average energy of all tracks is 513597931.3137464',\n",
    "            'expected_keywords': ['average', 'energy']\n",
    "        },\n",
    "        {\n",
    "            'query': 'Which artist appears most frequently?',\n",
    "            'expected_answer': 'The artist that appears most frequently is \"Bad Bunny\"',\n",
    "            'expected_keywords': ['most', 'frequently', 'artist', 'Bad Bunny']\n",
    "        },\n",
    "        {\n",
    "            'query': 'Which song has the highest valence?',\n",
    "            'expected_answer': 'The song with the highest valence is \"Seven\" ',\n",
    "            'expected_keywords': ['highest', 'valence', 'Seven']\n",
    "        },\n",
    "        {\n",
    "            'query': 'Which month had the most song releases?',\n",
    "            'expected_answer': 'The month with the most releases is January',\n",
    "            'expected_keywords': ['most', 'releases', 'August']\n",
    "        },\n",
    "        # {\n",
    "        #     'query': 'What is the average speechiness of tracks?',\n",
    "        #     'expected_answer': 'The average speechiness is Z%',\n",
    "        #     'expected_keywords': ['average', 'speechiness']\n",
    "        # },\n",
    "        # {\n",
    "        #     'query': 'Which track has the highest acousticness?',\n",
    "        #     'expected_answer': 'The track with the highest acousticness is \"vampire\" with 17%',\n",
    "        #     'expected_keywords': ['highest', 'acousticness', 'vampire']\n",
    "        # },\n",
    "        # {\n",
    "        #     'query': 'How many tracks are in minor key?',\n",
    "        #     'expected_answer': 'There are N tracks in minor key',\n",
    "        #     'expected_keywords': ['tracks', 'minor key']\n",
    "        # },\n",
    "        {\n",
    "            'query': 'What is the average number of Spotify playlists a track appears in?',\n",
    "            'expected_answer': 'The 5200.124868835249 is M playlists',\n",
    "            'expected_keywords': ['average', 'Spotify', 'playlists']\n",
    "        },\n",
    "        # {\n",
    "        #     'query': 'Which song has the highest BPM?',\n",
    "        #     'expected_answer': 'The song with the highest BPM is \"Cruel Summer\" with 170',\n",
    "        #     'expected_keywords': ['highest', 'BPM', 'Cruel Summer']\n",
    "        # },\n",
    "        # {\n",
    "        #     'query': 'Which song has the most Apple Music chart appearances?',\n",
    "        #     'expected_answer': 'The song with most Apple chart appearances is \"Cruel Summer\"',\n",
    "        #     'expected_keywords': ['most', 'Apple', 'charts', 'Cruel Summer']\n",
    "        # },\n",
    "        # {\n",
    "        #     'query': 'What is the average number of Deezer playlists per track?',\n",
    "        #     'expected_answer': 'The average is D playlists',\n",
    "        #     'expected_keywords': ['average', 'Deezer', 'playlists']\n",
    "        # },\n",
    "        {\n",
    "            'query': 'Which song had the earliest release date?',\n",
    "            'expected_answer': 'The song with the earliest release is \"Agudo Mï¿½ï¿½gi\"',\n",
    "            'expected_keywords': ['earliest', 'release', 'Agudo Mï¿½ï¿½gi']\n",
    "        },\n",
    "        # {\n",
    "        #     'query': 'Which song has the most instrumentalness?',\n",
    "        #     'expected_answer': 'The song with the most instrumentalness is \"WHERE SHE GOES\" with 63%',\n",
    "        #     'expected_keywords': ['most', 'instrumentalness', 'WHERE SHE GOES']\n",
    "        # },\n",
    "        {\n",
    "            'query': 'What is the total number of streams for all songs?',\n",
    "            'expected_answer': 'The total number of streams is 489458828542',\n",
    "            'expected_keywords': ['total', 'streams']\n",
    "        },\n",
    "        # {\n",
    "        #     'query': 'Which song has the lowest valence?',\n",
    "        #     'expected_answer': 'The song with the lowest valence is \"WHERE SHE GOES\" with 23%',\n",
    "        #     'expected_keywords': ['lowest', 'valence', 'WHERE SHE GOES']\n",
    "        # },\n",
    "        {\n",
    "            'query': 'Which artist has the highest average danceability across their songs?',\n",
    "            'expected_answer': 'The artist with highest average danceability is \"Latto\"',\n",
    "            'expected_keywords': ['highest', 'average', 'danceability', 'Latto']\n",
    "        },\n",
    "        {\n",
    "            'query': 'Which song appears in the most Spotify charts?',\n",
    "            'expected_answer': 'The song with most Spotify chart appearances is \"Seven\"',\n",
    "            'expected_keywords': ['most', 'Spotify', 'charts', 'Seven']\n",
    "        }\n",
    "    ]\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    # Initialize graph chain and evaluator\n",
    "    chain = graph_chain()\n",
    "    evaluator = RAGEvaluator(ground_truth_data)\n",
    "    \n",
    "    # Run evaluation\n",
    "    detailed_results, overall_metrics = evaluator.run_evaluation(chain)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Detailed Evaluation Results:\")\n",
    "    print(detailed_results)\n",
    "    print(\"\\nOverall Metrics:\")\n",
    "    print(overall_metrics)\n",
    "    \n",
    "    # Optional: Save results to CSV\n",
    "    detailed_results.to_csv('rag_evaluation_results.csv', index=False)\n",
    "    \n",
    "    return detailed_results, overall_metrics\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f1734b-5449-44b7-b5e9-c533f8951f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
